---
sidebar_position: 23
---

# تقریر کی شناخت اور قدرتی زبان کو سمجھنا (NLU)

ایک روبوٹ کے لیے گفتگو میں شامل ہونے کے لیے، اسے سب سے پہلے انسانی تقریر کی صوتی لہروں کو صارف کے ارادے کی ایک منظم سمجھ میں تبدیل کرنے کے قابل ہونا چاہیے۔ یہ عمل دو اہم مراحل کے ساتھ ایک پائپ لائن ہے: **خودکار تقریر کی شناخت (Automatic Speech Recognition - ASR)** اور **قدرتی زبان کو سمجھنا (Natural Language Understanding - NLU)**۔

## 1. خودکار تقریر کی شناخت (ASR)

ASR وہ ٹیکنالوجی ہے جو بولی جانے والی آڈیو کو متن میں تبدیل کرتی ہے۔ یہ سننے کے روبوٹک مساوی ہے۔

### ASR کیسے کام کرتا ہے

جدید ASR سسٹمز ڈیپ لرننگ پر مبنی ہیں۔ انہیں آڈیو ریکارڈنگز کے بڑے ڈیٹا سیٹس اور ان کے متعلقہ انسانی تصدیق شدہ ٹرانسکرپٹس پر تربیت دی جاتی ہے۔ ماڈل آڈیو سگنل (فونیمز، لہجے، انٹونیشنز) میں پیچیدہ نمونوں کو الفاظ اور جملوں سے نقشہ بنانا سیکھتا ہے۔

-   **ان پٹ (Input)**: ایک آڈیو سٹریم، عام طور پر روبوٹ پر ایک مائیکروفون اری سے۔
-   **آؤٹ پٹ (Output)**: متن کا ایک سٹرنگ۔

### روبوٹک سیاق و سباق میں ASR

ایک روبوٹ کے لیے، ASR اسمارٹ فون اسسٹنٹ کے مقابلے میں زیادہ چیلنجنگ ہے۔
-   **شور (Noise)**: روبوٹ کے اپنے موٹرز اور فینز شور پیدا کرتے ہیں، جو مائیکروفونز میں مداخلت کر سکتے ہیں۔
-   **فاصلہ (Distance)**: صارف کمرے کے پار سے روبوٹ سے بات کر رہا ہو گا، جس کے نتیجے میں ایک مدھم یا گونجتا ہوا سگنل ہو سکتا ہے۔
-   **مائیکروفون اریز (Microphone Arrays)**: ان مسائل کا مقابلہ کرنے کے لیے، روبوٹس اکثر ایک مائیکروفون اری سے لیس ہوتے ہیں۔ سگنل پروسیسنگ تکنیکوں (جیسے **بیمفارمنگ (beamforming)**) کا استعمال کرکے، روبوٹ بات کرنے والے شخص کی سمت میں اپنی "سماعت" کو مرکوز کر سکتا ہے اور پس منظر کے شور کو فلٹر کر سکتا ہے۔

مشہور ASR ٹول کٹس میں NVIDIA Riva، اور اوپن سورس ماڈلز جیسے OpenAI سے Whisper شامل ہیں۔

## 2. قدرتی زبان کو سمجھنا (NLU)

ایک بار جب صارف کی تقریر کو متن میں تبدیل کر دیا جاتا ہے، تو NLU سسٹم کو یہ معلوم کرنا ہوتا ہے کہ اس متن کا *کیا مطلب ہے*۔ NLU متن کے ایک ٹکڑے سے ارادے اور ہستیوں کو نکالنے کا عمل ہے۔

-   **ان پٹ (Input)**: متن کا ایک سٹرنگ (مثلاً، "روبوٹ، براہ کرم مجھے کچن کی میز سے سرخ کپ لا دو")۔
-   **آؤٹ پٹ (Output)**: صارف کے ارادے کی ایک منظم نمائندگی۔

### NLU کے کلیدی اجزاء

1.  **ارادے کی درجہ بندی (Intent Classification)**: NLU ماڈل سب سے پہلے صارف کے مجموعی مقصد کا تعین کرنے کی کوشش کرتا ہے۔ اوپر کی مثال میں، ارادہ `TransportObject` ہے۔

2.  **ہستی کا نکالنا (Entity Extraction)** (جسے سلاٹ فلنگ بھی کہا جاتا ہے): ماڈل پھر اس ارادے سے منسلک معلومات کے کلیدی ٹکڑوں (ہستیوں یا سلاٹس) کی شناخت کرتا ہے۔
    -   `object_to_transport`: "سرخ کپ"
    -   `source_location`: "کچن کی میز"
    -   `destination_location`: "میں" (یعنی، صارف کا موجودہ مقام)

NLU سسٹم کا حتمی آؤٹ پٹ JSON فارمیٹ میں کچھ اس طرح نظر آ سکتا ہے:
```json
{
  "intent": "TransportObject",
  "entities": {
    "object_to_transport": {
      "name": "cup",
      "color": "red"
    },
    "source_location": {
      "name": "table",
      "room": "kitchen"
    },
    "destination_location": "user"
  }
}
```

یہ منظم ڈیٹا پھر روبوٹ کے ٹاسک پلانر کو پاس کیا جا سکتا ہے، جو `TransportObject` روٹین کو کیسے عمل میں لانا جانتا ہے۔

## NLU میں LLMs کا عروج

روایتی طور پر، NLU سسٹمز کو ارادوں اور ہستیوں کے ایک مخصوص سیٹ کے لیے ایک کسٹم مشین لرننگ ماڈل کی تربیت کی ضرورت ہوتی تھی۔ آپ کو ہر ارادے کے لیے بہت سی مثالیں فراہم کرنی پڑتی تھیں جسے آپ روبوٹ سے سمجھنا چاہتے تھے۔

بڑے لسانی ماڈلز (LLMs) نے اس منظر نامے کو ڈرامائی طور پر تبدیل کر دیا ہے۔ ایک احتیاط سے تیار کردہ پرامپٹ کے ساتھ، اب آپ ایک طاقتور LLM (جیسے GPT-4) کو "زیرو-شاٹ" یا "فیو-شاٹ" طریقے سے NLU انجام دینے کے لیے استعمال کر سکتے ہیں، بغیر کسی مخصوص تربیت کے۔

آپ LLM کو ایک پرامپٹ فراہم کر سکتے ہیں جو مطلوبہ ارادوں اور ہستیوں کو بیان کرتا ہے اور اسے صارف کی بات چیت دیتا ہے۔ LLM اکثر اپنے پہلے ہی کوشش میں متن کو مطلوبہ منظم فارمیٹ میں صحیح طریقے سے پارس کرنے کے قابل ہوتا ہے۔ یہ گفتگو والے انٹرفیس کو تیار کرنا بہت تیز اور زیادہ لچکدار بناتا ہے، کیونکہ آپ پرامپٹ کو اپ ڈیٹ کرکے آسانی سے نئی صلاحیتیں شامل کر سکتے ہیں۔

روایتی NLU ماڈل استعمال کر رہے ہوں یا جدید LLM، مقصد وہی ہے: انسانی زبان کی خوبصورت، گندی، اور مبہم نوعیت کو درست، منظم کمانڈز میں تبدیل کرنا جس کی روبوٹ کو عمل کرنے کے لیے ضرورت ہوتی ہے۔