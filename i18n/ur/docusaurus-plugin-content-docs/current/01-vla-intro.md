---
sidebar_position: 1
---

# ہیومنائیڈز کے لیے وائس ٹو ایکشن (VLA)

ہیومنائیڈ روبوٹس میں صوتی کمانڈز کو ضم کرنا اس طریقے کو بدل دیتا ہے کہ انسان ذہین مشینوں کے ساتھ کیسے تعامل کرتے ہیں۔ وائس ٹو ایکشن (VLA) سسٹمز روبوٹس کو بولی جانے والی زبان کو سمجھنے، ارادے کی تشریح کرنے، اور جسمانی کاموں کو انجام دینے کے قابل بناتے ہیں، جس سے انسانی ہدایات اور روبوٹک رویے کے درمیان کا فرق ختم ہوتا ہے۔

## ہیومنائیڈز کے لیے VLA پائپ لائن

ہیومنائیڈ روبوٹ کے لیے ایک عام VLA پائپ لائن میں کئی مراحل شامل ہوتے ہیں:

1.  **تقریر کی شناخت (Speech Recognition - ASR)**: بولی جانے والی آڈیو کو متن میں تبدیل کرتا ہے۔ OpenAI Whisper جیسی ٹیکنالوجیز اس کے لیے انتہائی مؤثر ہیں۔
2.  **قدرتی زبان کو سمجھنا (Natural Language Understanding - NLU)**: پہچانے گئے متن پر عمل کرتا ہے تاکہ معنی، ارادے اور ہستیوں کو نکالا جا سکے۔ بڑے لسانی ماڈلز (LLMs) یہاں مرکزی حیثیت رکھتے ہیں، جو پیچیدہ کمانڈز اور سیاق و سباق کو سمجھنے کی صلاحیت رکھتے ہیں۔
3.  **ایکشن پلاننگ (Action Planning)**: سمجھے گئے ارادے کو روبوٹ کے اعمال کی ترتیب میں ترجمہ کرتا ہے۔ اس میں اکثر NLU آؤٹ پٹ کو مخصوص ROS 2 سروسز یا اعمال سے نقش کرنا شامل ہوتا ہے۔ ہیومنائیڈز کے لیے، اس میں بائپیڈل لوکوموشن، مینیپولیشن، یا تاثراتی اشارے شامل ہو سکتے ہیں۔
4.  **روبوٹ کا نفاذ (Robot Execution)**: روبوٹ کا کنٹرول سسٹم جسمانی دنیا میں منصوبہ بند اعمال کو انجام دیتا ہے۔

## تقریر کی شناخت کے لیے OpenAI Whisper

OpenAI Whisper ایک عام مقصد کا تقریر کی شناخت کا ماڈل ہے جو مختلف زبانوں میں آڈیو کو متن میں نقل کر سکتا ہے اور یہاں تک کہ ان کا ترجمہ بھی کر سکتا ہے۔ اس کی مضبوط کارکردگی اسے VLA سسٹم کے ASR جزو کے لیے ایک بہترین انتخاب بناتی ہے۔

## پلاننگ کے لیے بڑے لسانی ماڈلز (LLMs)

LLMs نے NLU اور ایکشن پلاننگ میں انقلاب برپا کر دیا ہے۔ LLMs کا فائدہ اٹھا کر، ہیومنائیڈ روبوٹس یہ کر سکتے ہیں:

-   **پیچیدہ کمانڈز کو سمجھیں**: مبہم یا کثیر مرحلہ ہدایات کی تشریح کریں جو سادہ کلیدی الفاظ سے آگے بڑھ جاتی ہیں۔
-   **سیاق و سباق کی آگاہی (Contextual awareness)**: سمجھ کو بہتر بنانے اور زیادہ مناسب جوابات پیدا کرنے کے لیے ڈائیلاگ ہسٹری کا استعمال کریں۔
-   **کوڈ جنریشن (LLM-to-ROS 2)**: کچھ LLMs قدرتی زبان کی کمانڈز کو براہ راست کوڈ سنیپٹس (جیسے `rclpy` کے لیے پائتھون) یا ROS 2 کمانڈز کی ترتیب میں ترجمہ کر سکتے ہیں، جس سے ایکشن پلاننگ کا مرحلہ آسان ہو جاتا ہے۔

## کیپ اسٹون ہیومنائیڈ وائس ایجنٹ

اس ماڈیول کا حتمی مقصد ایک کیپ اسٹون پروجیکٹ بنانا ہے: ایک ہیومنائیڈ وائس ایجنٹ۔ یہ ایجنٹ مکمل VLA پائپ لائن کا مظاہرہ کرے گا، جس سے صارفین کو صوتی کمانڈز جاری کرنے کی اجازت ملے گی جنہیں روبوٹ تشریح کرتا ہے اور ان پر عمل کرتا ہے، ممکنہ طور پر نیویگیشن، آبجیکٹ انٹریکشن، یا تاثراتی مواصلات شامل ہیں۔ یہ پروجیکٹ ROS 2، سمولیشن، اور جدید AI ماڈلز کے تصورات کو آپس میں جوڑتا ہے۔