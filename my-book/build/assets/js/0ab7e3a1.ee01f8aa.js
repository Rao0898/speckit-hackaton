"use strict";(globalThis.webpackChunkmy_book=globalThis.webpackChunkmy_book||[]).push([[3177],{6006(e,n,s){s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"gazebo-physics-sensors","title":"Physics and Sensor Simulation in Gazebo","description":"One of the greatest strengths of Gazebo is its ability to simulate the laws of physics and the behavior of common robotic sensors. This allows you to test your robot\'s control and perception algorithms in a realistic virtual environment before running them on hardware.","source":"@site/docs/12-gazebo-physics-sensors.md","sourceDirName":".","slug":"/gazebo-physics-sensors","permalink":"/my-book/docs/gazebo-physics-sensors","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12},"sidebar":"tutorialSidebar","previous":{"title":"URDF and SDF: Describing Your Robot","permalink":"/my-book/docs/urdf-sdf"},"next":{"title":"An Introduction to Unity for Robot Visualization and Simulation","permalink":"/my-book/docs/unity-for-robotics"}}');var r=s(2540),o=s(3023);const t={sidebar_position:12},a="Physics and Sensor Simulation in Gazebo",c={},l=[{value:"The Gazebo Physics Engine",id:"the-gazebo-physics-engine",level:2},{value:"Configuring Physics Properties",id:"configuring-physics-properties",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:2},{value:"Common Simulated Sensors",id:"common-simulated-sensors",level:3},{value:"Example: Adding a Camera Sensor in URDF",id:"example-adding-a-camera-sensor-in-urdf",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"physics-and-sensor-simulation-in-gazebo",children:"Physics and Sensor Simulation in Gazebo"})}),"\n",(0,r.jsx)(n.p,{children:"One of the greatest strengths of Gazebo is its ability to simulate the laws of physics and the behavior of common robotic sensors. This allows you to test your robot's control and perception algorithms in a realistic virtual environment before running them on hardware."}),"\n",(0,r.jsx)(n.h2,{id:"the-gazebo-physics-engine",children:"The Gazebo Physics Engine"}),"\n",(0,r.jsxs)(n.p,{children:["Gazebo uses a pluggable physics engine to simulate the physical interactions between objects in the world. The default engine is the ",(0,r.jsx)(n.strong,{children:"Open Dynamics Engine (ODE)"}),", which is a mature and widely-used open-source physics library."]}),"\n",(0,r.jsx)(n.p,{children:"The physics engine is responsible for:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gravity"}),": Making unsupported objects fall."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Collisions"}),": Detecting when two objects intersect and calculating the resulting forces and impulses to prevent them from passing through each other."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Friction"}),": Simulating the tangential forces that resist motion between contacting surfaces. This includes both static friction (the force needed to start an object moving) and kinetic friction (the force that resists ongoing motion)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Joint Constraints"}),": Enforcing the kinematic constraints of joints (e.g., ensuring a revolute joint only rotates around its defined axis)."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"configuring-physics-properties",children:"Configuring Physics Properties"}),"\n",(0,r.jsx)(n.p,{children:"You can tune the physics properties of your simulation in your world's SDF file and in your robot's URDF/SDF file."}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"In the World SDF"}),": You can set global physics parameters like the gravity vector and the default contact properties."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"In the Model URDF/SDF"}),": For each link's ",(0,r.jsx)(n.code,{children:"<collision>"})," tag, you can specify surface properties like friction coefficients (",(0,r.jsx)(n.code,{children:"mu"})," and ",(0,r.jsx)(n.code,{children:"mu2"}),") and contact stiffness and damping."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example: Setting friction for a link in URDF"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<link name="wheel">\r\n  <collision>\r\n    ...\r\n    <surface>\r\n      <friction>\r\n        <ode>\r\n          <mu>1.0</mu>  \x3c!-- Primary friction coefficient --\x3e\r\n          <mu2>0.5</mu2> \x3c!-- Secondary friction coefficient --\x3e\r\n        </ode>\r\n      </friction>\r\n    </surface>\r\n  </collision>\r\n  ...\r\n</link>\n'})}),"\n",(0,r.jsx)(n.h2,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,r.jsx)(n.p,{children:"Gazebo can simulate a wide variety of sensors, generating realistic data that is then published to ROS 2 topics. This allows you to test your entire perception pipeline in simulation."}),"\n",(0,r.jsx)(n.p,{children:"A sensor is typically attached to a link in your robot's model description file (URDF or SDF). You define the sensor's type, its properties, and the ROS 2 topic it should publish to."}),"\n",(0,r.jsx)(n.h3,{id:"common-simulated-sensors",children:"Common Simulated Sensors"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Camera"}),": Simulates a camera, publishing ",(0,r.jsx)(n.code,{children:"sensor_msgs/msg/Image"})," messages. You can configure its resolution, frame rate, and lens properties. Gazebo can also simulate depth cameras, which publish point clouds or depth images."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LiDAR / Laser Scanner"}),": Simulates a laser scanner by performing raycasting. It shoots out virtual laser beams and reports the distance to the first object they hit. It publishes ",(0,r.jsx)(n.code,{children:"sensor_msgs/msg/LaserScan"})," or ",(0,r.jsx)(n.code,{children:"sensor_msgs/msg/PointCloud2"})," messages."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"IMU (Inertial Measurement Unit)"}),": Simulates an accelerometer and a gyroscope. It provides data about the robot's linear acceleration and angular velocity, publishing ",(0,r.jsx)(n.code,{children:"sensor_msgs/msg/Imu"})," messages. The simulation can include realistic noise and bias to mimic a real-world IMU."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-adding-a-camera-sensor-in-urdf",children:"Example: Adding a Camera Sensor in URDF"}),"\n",(0,r.jsxs)(n.p,{children:["To add a sensor in URDF, you use a ",(0,r.jsx)(n.code,{children:"<gazebo>"})," tag that references the link the sensor is attached to."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<link name="camera_link">...</link>\r\n\r\n<joint name="camera_joint" type="fixed">\r\n  <parent link="base_link"/>\r\n  <child link="camera_link"/>\r\n</joint>\r\n\r\n<gazebo reference="camera_link">\r\n  <sensor type="camera" name="my_camera">\r\n    <update_rate>30.0</update_rate>\r\n    <camera>\r\n      <horizontal_fov>1.396</horizontal_fov>\r\n      <image>\r\n        <width>800</width>\r\n        <height>600</height>\r\n        <format>R8G8B8</format>\r\n      </image>\r\n    </camera>\r\n    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\r\n      <ros>\r\n        <namespace>/my_robot</namespace>\r\n        <remapping>image_raw:=camera/image</remapping>\r\n      </ros>\r\n    </plugin>\r\n  </sensor>\r\n</gazebo>\n'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"<sensor>"})}),": Defines the sensor. We set its ",(0,r.jsx)(n.code,{children:"type"}),' to "camera".']}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"<camera>"})}),": Contains the camera-specific parameters."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:(0,r.jsx)(n.code,{children:"<plugin>"})}),": This is the crucial part. The ",(0,r.jsx)(n.code,{children:"libgazebo_ros_camera.so"})," plugin is what connects the simulated camera to ROS 2. It takes the image data from Gazebo and publishes it as a ROS 2 message on the specified topic (",(0,r.jsx)(n.code,{children:"/my_robot/camera/image"}),")."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"By leveraging Gazebo's physics and sensor simulation capabilities, you can develop and validate your robot's most complex behaviors in a safe, repeatable, and efficient manner."})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},3023(e,n,s){s.d(n,{R:()=>t,x:()=>a});var i=s(3696);const r={},o=i.createContext(r);function t(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);